{
 "metadata": {
  "name": "sentiment analysis"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import enchant\n",
      "import re\n",
      "import numpy as np\n",
      "\"\"\"\n",
      "pos=['funny movie, i enjoyed it','luv it',\"highly recommend, wouldn't miss it for the world\",\"what an awesome movie\"]\n",
      "neg=['it sucks','boring, waste of time', 'i hate it,i cannot think of anyone who would like it',\"it's terriable, it sucks so much, i want my money and time back\"]\n",
      "\n",
      "pos_df=pd.DataFrame(pos, columns=[\"review\"])\n",
      "pos_df['polar']=1\n",
      "neg_df=pd.DataFrame(neg, columns=[\"review\"])\n",
      "neg_df['polar']=-1\n",
      "\n",
      "df=pos_df.append(neg_df,ignore_index=True) \n",
      "#--------------------\n",
      "\"\"\"\n",
      "#200+tag+emoticon(1+1)+len(sentence)\n",
      "## Read in data\n",
      "location_dir='/Users/zyenge/Dropbox/climatechangeviz/'\n",
      "train=pd.read_csv(location_dir+'trainingandtestdata/training.1600000.processed.noemoticon.csv',header=None)\n",
      "test=pd.read_csv(location_dir+'trainingandtestdata/testdata.manual.2009.06.14.csv',header=None)\n",
      "train_df=pd.DataFrame({'tweets':train[5],'polar':train[0]})\n",
      "test_df=pd.DataFrame({'tweets':test[5],'polar':test[0]})\n",
      "\n",
      "# a subset\n",
      "train_subset=pd.concat([train_df[:50],train_df[-50:]])\n",
      "train_subset\n",
      "\n",
      "\n",
      "#d.check('li')\n",
      "#d.suggest('booked')\n",
      "\n",
      "\n",
      "\n",
      "\"\"\"cleanning sequence:\n",
      "        0. remove url, @user,# -> ',', emoticon -- http://datagenetics.com/blog/october52012/index.html\n",
      "        2. if spell check is false:\n",
      "            if it's a word \"if re.match('^[a-zA-Z\\']+$',\"trainingLate\"):\"\n",
      "             try find in replace keyword dict\n",
      "             if not found: d.suggest[0]\n",
      "             elif no suggestion: shorten\n",
      "             then spell check...\n",
      "\n",
      "\n",
      "        3. tagging \n",
      "        4. remove '-','_','(',')', etc \n",
      "        5. stemming\n",
      "        #5. replace keywords (not enough training)\n",
      "\n",
      "    \"\"\"\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "#pos_string='i <3 justin b, u r the best! xoxo'\n",
      "#neg_string='it\\'s said that young people are blindly following jb..:('\n",
      "\n",
      "\n",
      "pos_emoticons=set([])\n",
      "neg_emoticons=set([])\n",
      "\n",
      "#smiley:\n",
      "with open(location_dir+'pos_emoticon.txt') as f:\n",
      "    for line in f:\n",
      "        pos_emoticons.add(line.rstrip('\\n'))\n",
      "#frowney:\n",
      "with open(location_dir+'neg_emoticon.txt') as f:\n",
      "    for line in f:\n",
      "        neg_emoticons.add(line.rstrip('\\n'))\n",
      "\n",
      "        \n",
      "\n",
      "\"\"\"1. remove url, @user, \n",
      "    2. # -> ',' \n",
      "    3. detect and remove emoticon\"\"\"\n",
      "\n",
      "def strip_tweet(tweet):\n",
      "    no_url=re.sub('((www\\.[^\\s]+)|(http[^\\s]+))','',tweet)\n",
      "    #print no_url\n",
      "    no_user=re.sub('@[^\\s]+','',no_url)\n",
      "    #print no_user\n",
      "    no_hashtag=re.sub(r'#([^\\s#]+)', r'\\1,', no_user)\n",
      "    #print no_hashtag\n",
      "    return no_hashtag   \n",
      "        \n",
      "def find_emoticons(tweet):\n",
      "    c=0\n",
      "    count=np.array([0,0])\n",
      "    while c< len(tweet):\n",
      "        two_char=tweet[c:c+2]\n",
      "        three_char=tweet[c:c+3]\n",
      "        if two_char in pos_emoticons:\n",
      "            tweet=tweet[:c]+' '+tweet[c+2:]\n",
      "            count+=np.array([1,0])\n",
      "        elif three_char in pos_emoticons:\n",
      "            tweet=tweet[:c]+' '+tweet[c+3:]\n",
      "            count+=np.array([1,0])\n",
      "        elif two_char in neg_emoticons:\n",
      "            tweet=tweet[:c]+' '+tweet[c+2:]\n",
      "            count+=np.array([0,1])\n",
      "        elif three_char in neg_emoticons:\n",
      "            tweet=tweet[:c]+' '+tweet[c+3:]\n",
      "            count+=np.array([0,1])\n",
      "        c+=1\n",
      "    return (tweet,count)\n",
      "\n",
      "\n",
      "emoticon_feature=[]\n",
      "for i in train_subset['tweets']:\n",
      "    tweet_pair=find_emoticons(strip_tweet(i))\n",
      "    emoticon_feature.append(tweet_pair[1])\n",
      "\n",
      "#emoticon_features=pd.DataFrame(emoticon_feature)\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "if re.match('^[a-zA-Z\\']+$',\"I'm\"):\n",
      "    print True\n",
      "else:\n",
      "    print False\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 137,
       "text": [
        "'\\nif re.match(\\'^[a-zA-Z\\']+$\\',\"I\\'m\"):\\n    print True\\nelse:\\n    print False\\n'"
       ]
      }
     ],
     "prompt_number": 137
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_tweet='@biggestfan#justin#lmao,http://somelink_to_someplace.com i <3 justin b, u r the best! xoxo'\n",
      "find_emoticons(strip_tweet(test_tweet))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 156,
       "text": [
        "(' i   justin b, u r the best! xoxo', array([1, 0]))"
       ]
      }
     ],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"spell check and replace word\n",
      "\n",
      "if spell check is false:\n",
      "            if it's a word \"if re.match('^[a-zA-Z\\']+$',\"trainingLate\"):\"\n",
      "             try find in replace keyword dict\n",
      "             if not found: d.suggest[0]\n",
      "             elif no suggestion: shorten\n",
      "             then spell check...\n",
      "             \n",
      "\"\"\"\n",
      "import string\n",
      "import yaml\n",
      "with open(\"web_words.yaml\", 'r') as f:\n",
      "    web_dict = yaml.load(f)\n",
      "\n",
      "puncset=set(string.punctuation) \n",
      "\n",
      "d=enchant.Dict('en-US')\n",
      "\n",
      "def shorten_word(word):\n",
      "    shortened=''\n",
      "    for c,i in enumerate(word):\n",
      "        if c<len(word)-1 and i!=word[c+1] or c==len(word)-1:\n",
      "            shortened=shortened+i\n",
      "    return shortened\n",
      "shorten_word('vvveeeeelll')\n",
      "\n",
      "\n",
      "def spell_check(tweet):\n",
      "    for w in tweet.split():\n",
      "        stripped_w=''.join([e if e not in puncset else '' for e in w])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print test_tweet\n",
      "pop_tweet=test_tweet\n",
      "tweet_list=test_tweet.split()\n",
      "l=0\n",
      "while l<len(tweet_list):\n",
      "    s_w=''.join([e if e not in puncset else '' for e in tweet_list[l]])\n",
      "    if d.check(s_w)!=True:\n",
      "        if s_w in web_dict:\n",
      "            tweet_list[l]=web_dict[s_w]\n",
      "        else:"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 169,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 169
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d=enchant.Dict('en-US')\n",
      "temp = 'luv!'.strip()\n",
      "d.suggest(temp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 177,
       "text": [
        "['Luvs', \"Lu's\", 'Lu', 'UV', 'lav', 'Luz', 'SUV', 'guv', 'lug']"
       ]
      }
     ],
     "prompt_number": 177
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import string\n",
      "puncset=set(string.punctuation) \n",
      "puncset"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 178,
       "text": [
        "set(['!', '#', '\"', '%', '$', \"'\", '&', ')', '(', '+', '*', '-', ',', '/', '.', ';', ':', '=', '<', '?', '>', '@', '[', ']', '\\\\', '_', '^', '`', '{', '}', '|', '~'])"
       ]
      }
     ],
     "prompt_number": 178
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 181,
       "text": [
        "'love'"
       ]
      }
     ],
     "prompt_number": 181
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}